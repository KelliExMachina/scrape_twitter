{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "referenced-overview",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p style=\"text-align:center;\"><img src=\"https://www.shareicon.net/data/512x512/2017/05/22/886198_twitter_512x512.png\" alt=\"Twitter Logo\"></p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<p style=\"text-align:center;\"><img src=\"https://www.shareicon.net/data/512x512/2017/05/22/886198_twitter_512x512.png\" alt=\"Twitter Logo\"></p>')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "statutory-mobility",
   "metadata": {},
   "source": [
    "# <div align='center'>Sentiment Analysis of Twitter Data</div>\n",
    "## <div align='center'>The New and Improved(?) Twitter API 2.0</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optimum-shade",
   "metadata": {},
   "source": [
    "Documentation:  \n",
    "[Complete Walk-thru on my Blog](https:www.girlexmachina.com)  \n",
    "[YouTube Playlist for all Parts]()  \n",
    "[Twitter API](https://developer.twitter.com/en/docs/developer-portal/overview)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compressed-richmond",
   "metadata": {},
   "source": [
    "## Background\n",
    "As an application, Twitter has opened up access to opinions and ideas like no other form of social media.  You can follow, tag, and mention anyone with an account to allow others to hear your views and opinions.  As of late, Twitter has been used by many activist to express their concerns to members of the media, government, and corporate america.  The true question is do companies utilize Twitter data for marketing feedback?  It's virtually free and can be a good thermomater for the feelings of the online crowd.\n",
    "\n",
    "<mark>I think it should go without saying that this is in no way a beginner tutorial.</mark>  Maneuvering the backwaters and bayous of the official Twitter documentation can be a difficult task, even for those who are already initiated.  It's possible that this code will run if you simply have a bearer token.  If you don't know what that is, then I strongly suggest you follow the walk-thru posted to my blog, and definitely the video series.  Otherwise you could be more confused than when you started.\n",
    "\n",
    "## Overview\n",
    "In this tutorial, we will analyze tweets before and after a movie trailer release to see if there was positive or negative sentiment towards the movie.  We will then compare our findings with box office numbers to see if our algorithm is accurate!  Scraping the tweets is the most difficult task in this tutorial.  Twitter severely limits the rate at which you can pull tweets (per 15 minutes), the total number of tweets, and also (to prevent the overwhelming of their API, force you to code for pagenation at 10 tweets per request.  As I'm using one of my many Twitter dev accounts, I'm going to try to pull as many extended tweets as possible.  Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "downtown-composer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os, requests, json\n",
    "import pandas as pd\n",
    "import tweepy as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "former-distinction",
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import twit_access_secret, twit_access_token, twit_api_key, twit_api_secret_key, twit_bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "recorded-raise",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"scraped_tweets/\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coastal-sight",
   "metadata": {},
   "source": [
    "## Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "genuine-natural",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giddy-up!\n"
     ]
    }
   ],
   "source": [
    "# This code block is from the official documentation (with a minor, personal touch!)\n",
    "auth = tp.OAuthHandler(\"twit_api_key\", \"twit_api_secret_key\")\n",
    "auth.set_access_token(\"twit_access_token\", \"twit_access_secret\")\n",
    "try:\n",
    "    twitter = tp.API(auth)\n",
    "    twitter.verify_credentials()\n",
    "    print('Giddy-up!')\n",
    "except:\n",
    "    print('Check your settings!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "official-conviction",
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "USER_ID = 15687962\n",
    "bearer_token = twit_bearer_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "applied-sleep",
   "metadata": {},
   "source": [
    "## Harvest Tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efficient-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = USER_ID\n",
    "url = \"https://api.twitter.com/2/users/{}/mentions\".format(user_id)\n",
    "\n",
    "EXPANSIONS = 'author_id,referenced_tweets.id,referenced_tweets.id.author_id,in_reply_to_user_id,attachments.media_keys,attachments.poll_ids,geo.place_id,entities.mentions.username'\n",
    "MEDIA_FIELDS = 'duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics'\n",
    "TWEET_FIELDS = 'created_at,author_id,public_metrics'\n",
    "USER_FIELDS = 'location,profile_image_url,verified'\n",
    "\n",
    "params =  {'max_results':100,'expansions': EXPANSIONS,'tweet.fields': TWEET_FIELDS,'user.fields': USER_FIELDS,'media.fields': MEDIA_FIELDS}\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "backed-spare",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "print(response.status_code)\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\n",
    "        \"Request returned an error: {} {}\".format(\n",
    "            response.status_code, response.text\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "still-expert",
   "metadata": {},
   "outputs": [],
   "source": [
    "json_response = response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "multiple-mainland",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tweets = pd.DataFrame(json_response['data'])\n",
    "df_meta = json_response['meta']\n",
    "df_tweets.to_csv(f'./scraped_tweets/marvel{i:02d}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "referenced-nicaragua",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'oldest_id': '1406063444789547008',\n",
       " 'newest_id': '1406098096212357124',\n",
       " 'result_count': 100,\n",
       " 'next_token': '7140dibdnow9c7btw3z0s077l00l7t8iprf8u7odj554o'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "paperback-tamil",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Round 1 saved!\n",
      "Round 2 saved!\n",
      "Round 3 saved!\n",
      "Round 4 saved!\n",
      "Round 5 saved!\n",
      "Round 6 saved!\n",
      "Round 7 saved!\n",
      "Round 8 saved!\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'next_token'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-b78cf7945e39>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://api.twitter.com/2/users/{}/mentions\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muser_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mtoken\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'pagination_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mjson_response\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'meta'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'next_token'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"GET\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheaders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'next_token'"
     ]
    }
   ],
   "source": [
    "url = \"https://api.twitter.com/2/users/{}/mentions\".format(user_id)\n",
    "for i in range(1,20):\n",
    "    token = json_response['meta']['next_token']\n",
    "    params['pagination_token']=json_response['meta']['next_token']\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "        json_response = response.json()\n",
    "        df_tweets = pd.DataFrame(json_response['data'])\n",
    "        df_meta = json_response['meta']\n",
    "        df_tweets.to_csv(f'./scraped_tweets/marvel{i:02d}.csv')\n",
    "        print(f'Round {i} saved!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "synthetic-drive",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweepy",
   "language": "python",
   "name": "tweepy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
