{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vertical-motor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML('<p style=\"text-align:center;\"><img src=\"https://www.shareicon.net/data/512x512/2017/05/22/886198_twitter_512x512.png\" alt=\"Twitter Logo\"></p>')) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ranking-excellence",
   "metadata": {},
   "source": [
    "# <div align='center'>Sentiment Analysis of Twitter Data</div>\n",
    "## <div align='center'>The New and Improved(?) Twitter API 2.0</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anticipated-myrtle",
   "metadata": {},
   "source": [
    "Documentation:  \n",
    "[Complete Walk-thru on my Blog](https:www.girlexmachina.com)  \n",
    "[YouTube Playlist for all Parts]()  \n",
    "[Twitter API](https://developer.twitter.com/en/docs/developer-portal/overview)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continued-composite",
   "metadata": {},
   "source": [
    "## Background\n",
    "As an application, Twitter has opened up access to opinions and ideas like no other form of social media.  You can follow, tag, and mention anyone with an account to allow others to hear your views and opinions.  As of late, Twitter has been used by many activist to express their concerns to members of the media, government, and corporate america.  The true question is do companies utilize Twitter data for marketing feedback?  It's virtually free and can be a good thermomater for the feelings of the online crowd.\n",
    "\n",
    "<mark>I think it should go without saying that this is in no way a beginner tutorial.</mark>  Maneuvering the backwaters and bayous of the official Twitter documentation can be a difficult task, even for those who are already initiated.  It's possible that this code will run if you simply have a bearer token.  If you don't know what that is, then I strongly suggest you follow the walk-thru posted to my blog, and definitely the video series.  Otherwise you could be more confused than when you started.\n",
    "\n",
    "## Overview\n",
    "In this tutorial, we will analyze tweets before and after a movie trailer release to see if there was positive or negative sentiment towards the movie.  We will then compare our findings with box office numbers to see if our algorithm is accurate!  Scraping the tweets is the most difficult task in this tutorial.  Twitter severely limits the rate at which you can pull tweets (per 15 minutes), the total number of tweets, and also (to prevent the overwhelming of their API, force you to code for pagenation at 10 tweets per request.  As I'm using one of my many Twitter dev accounts, I'm going to try to pull as many extended tweets as possible.  Let's get started!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cultural-mercy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard Libraries\n",
    "import os, requests, json\n",
    "import pandas as pd\n",
    "import tweepy as tp # just for the authenticatoin test.  Will eventually rewrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "labeled-advocacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import our passwords from our config.py file\n",
    "# Note: YOU WILL ONLY NEED THE BEARER_TOKEN FOR THIS EXERCISE, BUT THE OTHER KEYS ARE USED TO TEST YOUR ACCESS\n",
    "from config import twit_access_secret, twit_access_token, twit_api_key, twit_api_secret_key, twit_bearer_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "behind-california",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create directory for saving tweets.  You never want to lose your data when working with an API, especially if you must pay for it!\n",
    "os.makedirs(\"scraped_tweets/\",exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiovascular-midwest",
   "metadata": {},
   "source": [
    "## Check Authentication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "criminal-belgium",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Giddy-up!\n"
     ]
    }
   ],
   "source": [
    "# This code block is from the official documentation (with a minor, personal touch!)\n",
    "auth = tp.OAuthHandler(\"twit_api_key\", \"twit_api_secret_key\")\n",
    "auth.set_access_token(\"twit_access_token\", \"twit_access_secret\")\n",
    "try:\n",
    "    twitter = tp.API(auth)\n",
    "    twitter.verify_credentials()\n",
    "    print('Giddy-up!')\n",
    "except:\n",
    "    print('Check your settings!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cardiac-credit",
   "metadata": {},
   "source": [
    "[Convert Twitter IDs](https://tweeterid.com/)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unlimited-business",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert Twitter handle to user_id using site.  Will update this code in the future to do it though the API.\n",
    "#@marvel => 15687962\n",
    "i = 0\n",
    "USER_ID = 15687962\n",
    "bearer_token = twit_bearer_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "recreational-darwin",
   "metadata": {},
   "source": [
    "## Harvesting Tweets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "facial-roommate",
   "metadata": {},
   "source": [
    "Prerequisites:  \n",
    "- Twitter Developer account (requires approval)\n",
    "- Setup a development app within twitter account\n",
    "- App linked to Twitter Developer Labs (not available to everyone)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corrected-access",
   "metadata": {},
   "source": [
    "Coding modularly so that the code is easily updated in the event Twitter make further changes to the API\n",
    "I will also save this off to a .py file so that I can simply automate the scraping of tweets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "devoted-exercise",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_id = USER_ID\n",
    "url = \"https://api.twitter.com/2/users/{}/mentions\".format(user_id)\n",
    "\n",
    "EXPANSIONS = 'author_id,referenced_tweets.id,referenced_tweets.id.author_id,in_reply_to_user_id,attachments.media_keys,attachments.poll_ids,geo.place_id,entities.mentions.username'\n",
    "MEDIA_FIELDS = 'duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics'\n",
    "TWEET_FIELDS = 'created_at,author_id,public_metrics'\n",
    "USER_FIELDS = 'location,profile_image_url,verified'\n",
    "params =  {'max_results':100,'expansions': EXPANSIONS,'tweet.fields': TWEET_FIELDS,'user.fields': USER_FIELDS,'media.fields': MEDIA_FIELDS}\n",
    "\n",
    "headers = {\"Authorization\": \"Bearer {}\".format(bearer_token)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "drawn-better",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "print(response.status_code)\n",
    "if response.status_code != 200:\n",
    "    raise Exception(\n",
    "        \"Request returned an error: {} {}\".format(\n",
    "            response.status_code, response.text\n",
    "        )\n",
    "    )\n",
    "json_response = response.json()\n",
    "df_tweets = pd.DataFrame(json_response['data'])\n",
    "df_meta = json_response['meta']\n",
    "df_tweets.to_csv(f'./scraped_tweets/marvel{i:02d}.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "applicable-muscle",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_results': 100,\n",
       " 'expansions': 'author_id,referenced_tweets.id,referenced_tweets.id.author_id,in_reply_to_user_id,attachments.media_keys,attachments.poll_ids,geo.place_id,entities.mentions.username',\n",
       " 'tweet.fields': 'created_at,author_id,public_metrics',\n",
       " 'user.fields': 'location,profile_image_url,verified',\n",
       " 'media.fields': 'duration_ms,height,media_key,preview_image_url,type,url,width,public_metrics'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ready-velvet",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://api.twitter.com/2/users/{}/mentions\".format(user_id)\n",
    "for i in range(20):\n",
    "    token = json_response['meta']['next_token']\n",
    "    params['pagination_token']=json_response['meta']['next_token']\n",
    "    #print(url)\n",
    "    response = requests.request(\"GET\", url, headers=headers, params=params)\n",
    "    #print(response.status_code)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\n",
    "            \"Request returned an error: {} {}\".format(\n",
    "                response.status_code, response.text\n",
    "            )\n",
    "        )\n",
    "    else:\n",
    "\n",
    "        json_response = response.json()\n",
    "        df_tweets = pd.DataFrame(json_response['data'])\n",
    "        df_meta = json_response['meta']\n",
    "        df_tweets.to_csv(f'./scraped_tweets/marvel{i:02d}.csv')\n",
    "        print(f'Round {i} saved!')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tweepy",
   "language": "python",
   "name": "tweepy"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
